{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e4b2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aac582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(data, train_ratio = 0.8):\n",
    "    train_size = int(len(data) * train_ratio)\n",
    "    train_dataset = Subset(data, range(train_size))\n",
    "    test_dataset  = Subset(data, range(train_size, len(data)))\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9642629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, csv_file, window_size=30):\n",
    "        self.window_size = window_size\n",
    "\n",
    "        df = pd.read_csv(csv_file)\n",
    "        if \"date\" in df.columns:\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "            df = df.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "        num_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "        # --- Build a dense ID map: PAD=0, OOV=1, tickers start at 2\n",
    "        tickers = df[\"ticker\"].astype(str).unique().tolist()\n",
    "        PAD_ID, OOV_ID = 0, 1\n",
    "        sym2id = {s: i+2 for i, s in enumerate(tickers)}\n",
    "        self.PAD_ID, self.OOV_ID = PAD_ID, OOV_ID\n",
    "        self.num_embeddings = len(sym2id) + 2\n",
    "\n",
    "        df[\"ticker_id\"] = df[\"ticker\"].astype(str).map(lambda s: sym2id.get(s, OOV_ID)).astype(\"int64\")\n",
    "\n",
    "        # --- Normalize numeric features\n",
    "        X_num = df[num_cols].astype(\"float32\").copy()\n",
    "        X_num = (X_num\n",
    "                 .replace([float(\"inf\"), -float(\"inf\")], np.nan)\n",
    "                 .fillna(method=\"ffill\")\n",
    "                 .fillna(method=\"bfill\")\n",
    "                 .fillna(0.0))\n",
    "        self.mean = X_num.values.mean(axis=0)\n",
    "        self.std  = X_num.values.std(axis=0)\n",
    "        self.std[self.std < 1e-8] = 1e-8\n",
    "        Xz = (X_num.values - self.mean) / self.std\n",
    "\n",
    "        # --- Keep ticker ids SEPARATE (int64). Do NOT concatenate into float features.\n",
    "        self.Xz = Xz.astype(\"float32\")\n",
    "        self.ticker_ids = df[\"ticker_id\"].values.astype(\"int64\")\n",
    "\n",
    "        # --- Build per-ticker index ranges so windows don’t cross tickers\n",
    "        self.rows_by_ticker = df.groupby(\"ticker\", sort=False).indices\n",
    "        self.sample_index = []  # (start_row, end_row] per window, per ticker\n",
    "        for _, idxs in self.rows_by_ticker.items():\n",
    "            start, end = idxs.min(), idxs.max()\n",
    "            # windows entirely inside [start..end]\n",
    "            for i in range(start, end - window_size + 1):\n",
    "                self.sample_index.append(i)\n",
    "        self.target_col_idx = num_cols.index(\"close\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_index)\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        i = self.sample_index[k]\n",
    "        w = self.window_size\n",
    "        X = self.Xz[i:i+w, :]                                # (W, 5)\n",
    "        y = self.Xz[i+w-1, self.target_col_idx].astype(\"float32\")  # predict last step’s normalized close\n",
    "        ticker_id = int(self.ticker_ids[i+w-1])              # take the same row as y\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),            # (W, 5)\n",
    "            torch.tensor([y], dtype=torch.float32),          # (1,)\n",
    "            torch.tensor(ticker_id, dtype=torch.long),       # ()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c54409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 603890   Train Samples: 7549 Test Samples: 7549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/77yfqqcs31q66w55b3yfyqs80000gn/T/ipykernel_45882/3513841447.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  .fillna(method=\"ffill\")\n",
      "/var/folders/vp/77yfqqcs31q66w55b3yfyqs80000gn/T/ipykernel_45882/3513841447.py:26: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  .fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "stock_dataset = StockDataset(\"./data/S&P500/all_stocks_5yr.csv\", 30)\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset, test_dataset = test_train_split(stock_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Total Samples: {len(stock_dataset)}   Train Samples: {len(train_loader)} Test Samples: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e57db7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(predictions, stddev, mean, range=30):\n",
    "    for prediction, expected in predictions:\n",
    "        prediction = prediction * stddev + mean\n",
    "        expected = expected * stddev + mean\n",
    "        print(f\"PREDICTION: {prediction}    EXPECTED: {expected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b60b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMReg(nn.Module):\n",
    "    def __init__(self, in_feat, hidden_size=64, layers=2, num_tickers=1000, emb_dim=16):\n",
    "        super().__init__()\n",
    "        self.ticker_emb = nn.Embedding(num_tickers, emb_dim)\n",
    "        self.lstm = nn.LSTM(input_size=in_feat + emb_dim, hidden_size=hidden_size, num_layers=layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, ticker_ids):\n",
    "        # x: (B, W, in_feat), ticker_ids: (B,)\n",
    "        emb = self.ticker_emb(ticker_ids)           # (B, emb_dim)\n",
    "        emb = emb.unsqueeze(1).expand(-1, x.size(1), -1)  # (B, W, emb_dim)\n",
    "        x = torch.cat([x, emb], dim=-1)             # concat ticker embedding to each timestep\n",
    "        out, _ = self.lstm(x)\n",
    "        last_out = out[:, -1, :]\n",
    "        return self.fc(last_out)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMReg(in_feat=5, hidden_size=64, layers=1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b71e27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SmoothL1Loss()\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.01\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b90f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, model, criterion, optimizer=None, device=\"cpu\"):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    total_loss, n = 0.0, 0\n",
    "    predictions = []\n",
    "\n",
    "    ctx = torch.enable_grad() if is_train else torch.no_grad()\n",
    "    with ctx:\n",
    "        for X, y, ticker in loader:\n",
    "            X = X.to(device, non_blocking=True)           # (B, W, F_num)\n",
    "            y = y.to(device, non_blocking=True)           # (B, 1)\n",
    "            ticker = ticker.to(device, non_blocking=True) # (B,) int64 for Embedding\n",
    "\n",
    "           \n",
    "            pred = model(X, ticker)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            if is_train:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            # Accounting\n",
    "            bs = X.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            n += bs\n",
    "\n",
    "            # Collect predictions (detach -> cpu -> list/np)\n",
    "            predictions.append(pred.detach().cpu())\n",
    "\n",
    "            # If you want targets too:\n",
    "            # targets.append(y.detach().cpu())\n",
    "\n",
    "    # Stack to a single tensor (shape: (N, 1))\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    # targets = torch.cat(targets, dim=0) if targets else None\n",
    "\n",
    "    return total_loss / max(n, 1), predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eb89117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train 0.0130 | val 0.0132\n",
      "Epoch 02 | train 0.0021 | val 0.0048\n",
      "Epoch 03 | train 0.0010 | val 0.0029\n",
      "Epoch 04 | train 0.0008 | val 0.0032\n",
      "Epoch 05 | train 0.0013 | val 0.0029\n",
      "Epoch 06 | train 0.0015 | val 0.0035\n",
      "Epoch 07 | train 0.0004 | val 0.0025\n",
      "Epoch 08 | train 0.0003 | val 0.0023\n",
      "Epoch 09 | train 0.0006 | val 0.0056\n",
      "Epoch 10 | train 0.0005 | val 0.0044\n",
      "Epoch 11 | train 0.0011 | val 0.0030\n",
      "Epoch 12 | train 0.0003 | val 0.0041\n",
      "Epoch 13 | train 0.0003 | val 0.0024\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "best_val = float('inf')\n",
    "patience, bad_epochs = 5, 0\n",
    "best_state = None\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, _ = run_epoch(train_loader, model, criterion, optimizer, device)\n",
    "    val_loss, _   = run_epoch(val_loader,   model, criterion, None,      device)\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val - 1e-6:\n",
    "        best_val = val_loss\n",
    "        best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "        bad_epochs = 0\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train {train_loss:.4f} | val {val_loss:.4f}\")\n",
    "\n",
    "    if bad_epochs >= patience:\n",
    "        print(\"Early stopping.\")\n",
    "        break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "833cc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f822fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        open       high        low      close     volume ticker\n",
      "0  27.847500  27.860001  26.837500  27.332500  212818400   AAPL\n",
      "1  27.072500  27.162500  26.352501  26.562500  257142000   AAPL\n",
      "2  26.635000  26.857500  26.157499  26.565001  263188400   AAPL\n",
      "3  26.799999  27.049999  26.674999  26.937500  160423600   AAPL\n",
      "4  27.307501  28.037500  27.174999  27.972500  237458000   AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/77yfqqcs31q66w55b3yfyqs80000gn/T/ipykernel_45882/3513841447.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  .fillna(method=\"ffill\")\n",
      "/var/folders/vp/77yfqqcs31q66w55b3yfyqs80000gn/T/ipykernel_45882/3513841447.py:26: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  .fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/TESTDATA/top_10_stock_data.csv\")\n",
    "feature_order = [\"open\", \"high\", \"low\", \"close\", \"volume\", \"ticker\"]\n",
    "df = df[feature_order]\n",
    "print(df.head())\n",
    "test_dataset = StockDataset(\"./data/TESTDATA/top_10_stock_data.csv\", 30)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7040aeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0025987274087182844\n"
     ]
    }
   ],
   "source": [
    "state = torch.load(\"model.pt\", weights_only=True)\n",
    "test_model = LSTMReg(in_feat=5, hidden_size=64, layers=1).to(device)\n",
    "test_model.load_state_dict(state)\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss, predictions = run_epoch(test_loader, test_model, criterion, None, device)\n",
    "print(\"Test loss:\", test_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa211936",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display_results(predictions, test_dataset\u001b[38;5;241m.\u001b[39mstd[\u001b[38;5;241m3\u001b[39m], test_dataset\u001b[38;5;241m.\u001b[39mmean[\u001b[38;5;241m3\u001b[39m])\n",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m, in \u001b[0;36mdisplay_results\u001b[0;34m(predictions, stddev, mean, range)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdisplay_results\u001b[39m(predictions, stddev, mean, \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prediction, expected \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[1;32m      3\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m prediction \u001b[38;5;241m*\u001b[39m stddev \u001b[38;5;241m+\u001b[39m mean\n\u001b[1;32m      4\u001b[0m         expected \u001b[38;5;241m=\u001b[39m expected \u001b[38;5;241m*\u001b[39m stddev \u001b[38;5;241m+\u001b[39m mean\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "display_results(predictions, test_dataset.std[3], test_dataset.mean[3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
